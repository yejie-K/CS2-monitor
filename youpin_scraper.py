import pandas as pd
from playwright.sync_api import sync_playwright
import os
import time
import re
from datetime import datetime

# ================= é…ç½®åŒº =================
INPUT_FILE = "task.xlsx"       
COOKIE_FILE = "uu_auth.json"
# =========================================

def get_target_skins():
    """
    è§£æ task.xlsx
    è¿”å›åˆ—è¡¨ç»“æ„: [{"name": "é¥°å“å", "use_arrow": True/False}, ...]
    """
    targets = []
    try:
        df = pd.read_excel(INPUT_FILE, header=None)
        
        # 1. ç¬¬ä¸€è¡Œç›®æ ‡ï¼šè¿½åŠ  "(ä¹…ç»æ²™åœº)"ï¼Œå¹¶ä¸”éœ€è¦ä¸‹ç®­å¤´é€‰æ‹©
        row1_raw = df.iloc[0, 1:].dropna().astype(str).tolist()
        for t in row1_raw:
            clean_name = t.strip()
            if clean_name:
                targets.append({
                    "name": f"{clean_name} (ä¹…ç»æ²™åœº)",
                    "use_arrow": True  # éœ€è¦æŒ‰ç®­å¤´
                })
        
        # 2. åå››ä¸ªç›®æ ‡ï¼ˆç¬¬äºŒåˆ—ï¼‰ï¼šä¿æŒåŸæ ·ï¼Œä¸éœ€è¦ä¸‹ç®­å¤´
        col2_raw = df.iloc[2:6, 1].dropna().astype(str).tolist()
        for t in col2_raw:
            clean_name = t.strip()
            if clean_name:
                targets.append({
                    "name": clean_name,
                    "use_arrow": False # ä¸éœ€è¦æŒ‰ç®­å¤´
                })
        
        print(f"ğŸ“‹ [ä»»åŠ¡åŠ è½½] å…± {len(targets)} ä¸ªç›®æ ‡")
        return targets
    except Exception as e:
        print(f"âŒ è¯»å– Excel å¤±è´¥: {e}")
        return []

def run_scraper():
    target_items = get_target_skins() # è·å–å¸¦æœ‰é…ç½®çš„ç›®æ ‡åˆ—è¡¨
    if not target_items: return

    file_timestamp = datetime.now().strftime('%m%d(%H)')
    final_stats_map = {} 

    with sync_playwright() as p:
        print("ğŸš€ [å¯åŠ¨] V18 ä¿®å¤ç‰ˆï¼šé’ˆå¯¹åå››é¡¹ç§»é™¤å¤šä½™ä¸‹ç®­å¤´æ“ä½œ")
        
        #browser = p.chromium.launch(headless=False, args=["--disable-blink-features=AutomationControlled"])
        # ä¿®æ”¹ç‚¹ï¼šåŠ ä¸Š channel="msedge"ï¼Œè®©å®ƒä½¿ç”¨ç”µè„‘è‡ªå¸¦çš„ Edge æµè§ˆå™¨
        browser = p.chromium.launch(channel="msedge", headless=False, args=["--disable-blink-features=AutomationControlled"])
        if os.path.exists(COOKIE_FILE):
            context = browser.new_context(storage_state=COOKIE_FILE)
        else:
            context = browser.new_context()
            
        page = context.new_page()
        page.set_viewport_size({"width": 1920, "height": 1080})

        # âš¡ï¸ æ‹¦æˆªå›¾ç‰‡/å­—ä½“ï¼Œæå‡é€Ÿåº¦
        page.route("**/*", lambda route: route.abort() 
                   if route.request.resource_type in ["image", "media", "font"] 
                   else route.continue_())

        # ============================================================
        # ğŸ‘‡ æŠ“å–å‡½æ•°
        # ============================================================
        def scrape_sale_prices():
            print("   ğŸ“¥ æå–æ•°æ®ä¸­...")
            # æ— éœ€æ»šåŠ¨ï¼Œç›´æ¥ç­‰å¾…è¡¨æ ¼
            try:
                page.wait_for_selector("tr.ant-table-row", timeout=3000)
            except: pass

            rows = page.locator("tr.ant-table-row").all()
            prices = []
            seen_hashes = set()

            for row in rows:
                try:
                    if not row.is_visible(): continue
                    full_text = row.inner_text().replace("\n", " ")
                    
                    h = hash(full_text)
                    if h in seen_hashes: continue
                    seen_hashes.add(h)

                    if "Â¥" not in full_text and "ï¿¥" not in full_text: continue
                    p = re.search(r'[Â¥ï¿¥]\s*([\d\.]+)', full_text)
                    if p:
                        prices.append(float(p.group(1)))
                except: continue
            return prices

        # ============================================================
        # ğŸ”„ ä¸»å¾ªç¯
        # ============================================================
        for idx, item_data in enumerate(target_items):
            skin_name = item_data["name"]
            use_arrow = item_data["use_arrow"]
            
            print(f"\n[{idx+1}/{len(target_items)}] æ­£åœ¨å¤„ç†: {skin_name}")
            
            try:
                page.goto("https://www.youpin898.com/market")
                
                # äº¤äº’é€»è¾‘
                try:
                    sb = page.wait_for_selector("input.ant-input, input[class*='search']", state="visible", timeout=10000)
                    sb.click()
                    sb.fill(skin_name) 
                    
                    page.wait_for_timeout(500) 
                    
                    # å…³é”®ä¿®å¤ï¼šæ ¹æ® use_arrow å†³å®šæ˜¯å¦æŒ‰æ–¹å‘é”®
                    if use_arrow:
                        sb.press("ArrowDown") # é€‰ä¸­ç¬¬ä¸€ä¸ªè”æƒ³è¯
                        page.wait_for_timeout(200)
                    
                    sb.press("Enter")     # è·³è½¬
                    
                    try:
                        page.wait_for_selector("tr.ant-table-row", timeout=5000)
                    except:
                        print("   âš ï¸ è¡¨æ ¼æœªåŠ è½½")
                        final_stats_map[skin_name] = None
                        continue

                except Exception as e:
                    print(f"   âŒ äº¤äº’å¤±è´¥: {e}")
                    final_stats_map[skin_name] = None
                    continue

                # æŠ“å–
                prices = scrape_sale_prices()
                
                # ç»Ÿè®¡
                if prices:
                    stats = {
                        "æœ€é«˜": max(prices),
                        "æœ€ä½": min(prices),
                        "å‡å€¼": round(sum(prices) / len(prices), 2),
                        "ä¸­ä½æ•°": sorted(prices)[len(prices) // 2]
                    }
                    print(f"   âœ… æœ€ä½: {stats['æœ€ä½']} | å‡å€¼: {stats['å‡å€¼']}")
                    final_stats_map[skin_name] = stats
                else:
                    print("   âš ï¸ æ— æ•°æ®")
                    final_stats_map[skin_name] = None
            
            except Exception as e:
                print(f"   âŒ å¼‚å¸¸: {e}")
                final_stats_map[skin_name] = None

        browser.close()

    # ==========================================
    # ğŸ’¾ Excel ç”Ÿæˆ (å·²ä¿®å¤é‡å¤è¡Œé—®é¢˜)
    # ==========================================
    output_filename = f"æ‰‹å¥—åŠå…¶ä¸‹çº§-uu {file_timestamp}.xlsx"
    print(f"\nğŸ“Š ç”Ÿæˆ Excel: {output_filename}")

    try:
        indicators = ["æœ€é«˜", "æœ€ä½", "å‡å€¼", "ä¸­ä½æ•°"]
        data_dict = {}
        # è¿™é‡Œçš„å¾ªç¯ä¹Ÿè¦æ”¹ï¼Œä»å­—å…¸é‡Œå– name
        for item in target_items:
            skin = item["name"]
            stats = final_stats_map.get(skin)
            if stats:
                data_dict[skin] = [stats[k] for k in indicators]
            else:
                data_dict[skin] = ["-", "-", "-", "-"]

        df = pd.DataFrame(data_dict, index=indicators)

        with pd.ExcelWriter(output_filename, engine='xlsxwriter') as writer:
            # 1. å†™å…¥åŸå§‹æ•°æ®
            df.to_excel(writer, sheet_name="ç»Ÿè®¡æ•°æ®")
            
            workbook = writer.book
            worksheet = writer.sheets["ç»Ÿè®¡æ•°æ®"]
            yellow_fmt = workbook.add_format({'bg_color': '#FFFF00', 'bold': True})
            
            # 2. è®¡ç®—æ­£ç¡®çš„è¡Œå·
            target_excel_row = 2 
            
            # 3. éå†è¯¥è¡Œè¿›è¡Œæ ‡é»„
            for col_idx in range(df.shape[1] + 1):
                if col_idx == 0:
                    worksheet.write(target_excel_row, col_idx, "æœ€ä½", yellow_fmt)
                else:
                    val = df.iloc[1, col_idx - 1]
                    worksheet.write(target_excel_row, col_idx, val, yellow_fmt)

        print("ğŸ‰ å…¨éƒ¨å®Œæˆï¼")

    except Exception as e:
        print(f"âŒ Excel å¤±è´¥: {e}")

# å°è£…ä¾›ä¸»ç¨‹åºè°ƒç”¨
def main_task():
    run_scraper()

if __name__ == "__main__":
    main_task()