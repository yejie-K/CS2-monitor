import pandas as pd
from playwright.sync_api import sync_playwright
import re
import json
import os
import time
from datetime import datetime
from urllib.parse import quote

# ================= é…ç½®åŒº =================
INPUT_FILE = "task.xlsx"  # ä½ çš„ä»»åŠ¡æ–‡ä»¶
DB_FILE = "gun_keys.json" # IDç¼“å­˜æ–‡ä»¶
# =========================================

def load_db():
    if not os.path.exists(DB_FILE): return {}
    try:
        with open(DB_FILE, "r", encoding="utf-8") as f: return json.load(f)
    except: return {}

def save_db(data):
    try:
        with open(DB_FILE, "w", encoding="utf-8") as f:
            json.dump(data, f, ensure_ascii=False, indent=4)
    except: pass

def get_target_skins():
    """è§£æ task.xlsx è·å–ç›®æ ‡é¥°å“åˆ—è¡¨"""
    targets = []
    try:
        # è¯»å– Excelï¼Œä¸å¸¦è¡¨å¤´ï¼Œæ–¹ä¾¿æŒ‰è¡Œç´¢å¼•
        df = pd.read_excel(INPUT_FILE, header=None)
        
        # 1. è·å–ç¬¬ä¸€è¡Œï¼ˆå¿½ç•¥ç¬¬ä¸€åˆ—ï¼‰
        row1_targets = df.iloc[0, 1:].dropna().astype(str).tolist()
        targets.extend([t.strip() for t in row1_targets if t.strip()])
        
        # 2. è·å–ç¬¬3-6è¡Œçš„ç¬¬äºŒåˆ—
        col2_targets = df.iloc[2:6, 1].dropna().astype(str).tolist()
        targets.extend([t.strip() for t in col2_targets if t.strip()])
        
        print(f"ğŸ“‹ å·²åŠ è½½ {len(targets)} ä¸ªç›®æ ‡: {targets}")
        return targets
    except Exception as e:
        print(f"âŒ è¯»å– {INPUT_FILE} å¤±è´¥: {e}")
        return []

def run_scraper():
    target_skins = get_target_skins()
    if not target_skins: return

    file_timestamp = datetime.now().strftime('%m%d(%H)')
    db = load_db()
    
    # ç”¨äºå­˜å‚¨æœ€ç»ˆç»Ÿè®¡ç»“æœçš„å­—å…¸
    final_stats = {}

    with sync_playwright() as p:
        print("ğŸš€ å¯åŠ¨æµè§ˆå™¨...")
        # å¯åŠ¨å‚æ•°ä¼˜åŒ–
        #browser = p.chromium.launch(headless=False, args=["--disable-blink-features=AutomationControlled"])
        # ä¿®æ”¹ç‚¹ï¼šåŠ ä¸Š channel="msedge"ï¼Œè®©å®ƒä½¿ç”¨ç”µè„‘è‡ªå¸¦çš„ Edge æµè§ˆå™¨
        browser = p.chromium.launch(channel="msedge", headless=False, args=["--disable-blink-features=AutomationControlled"])
        
        # å¦‚æœæ²¡æœ‰ buff_auth.jsonï¼Œè¿™é‡Œä¼šæŠ¥é”™ï¼Œè¯·ç¡®ä¿å·²ç™»å½•å¹¶ä¿å­˜äº†çŠ¶æ€
        # å¦‚æœç¬¬ä¸€æ¬¡è¿è¡Œæ²¡çŠ¶æ€ï¼Œå¯ä»¥å…ˆæŠŠ storage_state å»æ‰æ‰‹åŠ¨ç™»å½•ä¸€æ¬¡
        try:
            context = browser.new_context(storage_state="buff_auth.json")
        except:
            print("âš ï¸ æœªæ‰¾åˆ°ç™»å½•ä¿¡æ¯ buff_auth.jsonï¼Œå°†ä»¥æœªç™»å½•æ¨¡å¼è¿è¡Œï¼ˆå¯èƒ½æ— æ³•æŸ¥çœ‹ä»·æ ¼ï¼‰")
            context = browser.new_context()

        page = context.new_page()
        # æ‹¦æˆªå›¾ç‰‡ï¼ŒåŠ å¿«é€Ÿåº¦
        page.route("**/*.{png,jpg,jpeg,gif,webp}", lambda route: route.abort())

        # å½“å‰æ­£åœ¨å¤„ç†çš„ä¸´æ—¶ä»·æ ¼åˆ—è¡¨
        current_prices = []

        # --- æ•°æ®æ‹¦æˆªå™¨ ---
        def handle_response(response):
            if "goods/sell_order" in response.url and response.status == 200:
                try:
                    data = response.json()
                    items = data.get('data', {}).get('items', [])
                    print(f"   ---> ğŸ“¦ æ•è·æ•°æ®: {len(items)} æ¡")
                    for item in items:
                        price = item.get('price')
                        if price:
                            current_prices.append(float(price))
                except: pass

        page.on("response", handle_response)

        # ================= å¾ªç¯å¤„ç†æ¯ä¸ªé¥°å“ =================
        for idx, skin_name in enumerate(target_skins):
            print(f"\n[{idx+1}/{len(target_skins)}] æ­£åœ¨å¤„ç†: {skin_name}")
            
            # 1. è·å– ID (å¦‚æœæœ¬åœ°æ²¡æœ‰ï¼Œåˆ™é€šè¿‡æœç´¢æ äº¤äº’è·å–)
            goods_id = db.get(skin_name)
            if not goods_id:
                print(f"   âš ï¸ æœ¬åœ°æ— IDï¼Œæ­£åœ¨æ‰§è¡Œï¼šè¾“å…¥ -> ä¸‹ç®­å¤´ -> å›è½¦...")
                
                # æ¯æ¬¡éœ€è¦æœç´¢ ID æ—¶ï¼Œå¼ºåˆ¶å›åˆ°å¸‚åœºé¦–é¡µï¼Œç¡®ä¿ä»â€œåŸæ¥ç•Œé¢â€å¼€å§‹
                # è¿™æ ·å¯ä»¥ä¿è¯æœç´¢ç¯å¢ƒä¸€è‡´ï¼Œä¸” wait_for_url é€»è¾‘æ›´å‡†ç¡®
                page.goto("https://buff.163.com/market/csgo#tab=selling")
                
                try:
                    # å®šä½æœç´¢æ¡† (Buff é€šç”¨æœç´¢æ¡†é€šå¸¸ name='search')
                    search_input = page.locator("input[name='search']").first
                    
                    # ç¡®ä¿æœç´¢æ¡†å¯è§
                    search_input.wait_for(state="visible", timeout=5000)
                    
                    # æ¸…ç©ºå¹¶è¾“å…¥
                    search_input.click()
                    search_input.clear()
                    search_input.fill(skin_name)
                    
                    # === å…³é”®é€»è¾‘ä¿®æ”¹å¼€å§‹ ===
                    # 1. ç­‰å¾…ä¸€ä¸‹ï¼Œè®© Buff åç«¯è¿”å›è”æƒ³è¯ (æ¨¡æ‹Ÿäººç±»ååº”)
                    time.sleep(1.5) 
                    
                    # 2. æŒ‰ä¸‹æ–¹å‘é”®ä¸‹ (é€‰ä¸­ç¬¬ä¸€ä¸ªè”æƒ³è¯)
                    page.keyboard.press("ArrowDown")
                    time.sleep(0.5) 
                    
                    # 3. æŒ‰ä¸‹å›è½¦ (è¿›å…¥å•†å“é¡µ)
                    page.keyboard.press("Enter")
                    # === å…³é”®é€»è¾‘ä¿®æ”¹ç»“æŸ ===

                    # ç­‰å¾…URLå˜åŒ–åŒ…å« goods id
                    # Buff å•†å“é¡µ URL æ ¼å¼é€šå¸¸æ˜¯ .../goods/12345...
                    page.wait_for_url(re.compile(r".*/goods/\d+"), timeout=8000)
                    
                    match = re.search(r"goods/(\d+)", page.url)
                    if match:
                        goods_id = match.group(1)
                        db[skin_name] = goods_id
                        save_db(db)
                        print(f"   âœ… æ•è·æˆåŠŸ ID: {goods_id}")
                    else:
                        print("   âŒ è·³è½¬åæœªå‘ç°IDç‰¹å¾ï¼Œè·³è¿‡")
                        final_stats[skin_name] = None
                        continue
                except Exception as e:
                    print(f"   âŒ æœç´¢äº¤äº’è¶…æ—¶æˆ–å¤±è´¥: {e}")
                    final_stats[skin_name] = None
                    continue

            # 2. æŠ“å–æ•°æ® (å·²çŸ¥ ID åç›´æ¥æ‹¼æ¥ URLï¼Œæ•ˆç‡æ›´é«˜)
            current_prices = [] 
            base_url = f"https://buff.163.com/goods/{goods_id}"
            
            page_nums = [1, 2] 
            
            for p_num in page_nums:
                target_url = f"{base_url}?from=market#tab=selling&page_num={p_num}"
                page.goto(target_url)
                try:
                    with page.expect_response(lambda r: "goods/sell_order" in r.url and r.status == 200, timeout=5000):
                        if p_num == 1: page.reload()
                        else: pass 
                except:
                    pass
                time.sleep(0.5 + (0.2 * p_num))

            # 3. è®¡ç®—ç»Ÿè®¡æŒ‡æ ‡
            if current_prices:
                stats = {
                    "æœ€é«˜": max(current_prices),
                    "æœ€ä½": min(current_prices),
                    "å‡å€¼": round(sum(current_prices) / len(current_prices), 2),
                    "ä¸­ä½æ•°": sorted(current_prices)[len(current_prices) // 2]
                }
                print(f"   âœ… ç»Ÿè®¡å®Œæˆ: æœ€ä½ {stats['æœ€ä½']}")
                final_stats[skin_name] = stats
            else:
                print("   âš ï¸ æ— åœ¨å”®æ•°æ®")
                final_stats[skin_name] = {"æœ€é«˜": 0, "æœ€ä½": 0, "å‡å€¼": 0, "ä¸­ä½æ•°": 0}

            time.sleep(1)

        browser.close()

    # ================= Excel ç”Ÿæˆé€»è¾‘ =================
    output_filename = f"BUFF_æ•°æ®_{file_timestamp}.xlsx"
    print(f"\nğŸ“Š æ­£åœ¨ç”Ÿæˆ: {output_filename}")

    try:
        data_for_df = {}
        indicators = ["æœ€é«˜", "æœ€ä½", "å‡å€¼", "ä¸­ä½æ•°"]
        
        for skin in target_skins:
            stats = final_stats.get(skin)
            if stats:
                data_for_df[skin] = [stats[k] for k in indicators]
            else:
                data_for_df[skin] = ["-", "-", "-", "-"]

        df = pd.DataFrame(data_for_df, index=indicators)

        with pd.ExcelWriter(output_filename, engine='xlsxwriter') as writer:
            df.to_excel(writer, sheet_name="ç»Ÿè®¡æ•°æ®")
            
            workbook = writer.book
            worksheet = writer.sheets["ç»Ÿè®¡æ•°æ®"]
            yellow_fmt = workbook.add_format({'bg_color': '#FFFF00', 'bold': True})
            
            target_row_idx = 2 
            
            for col_idx, col_name in enumerate(df.columns):
                val = df.loc["æœ€ä½", col_name]
                worksheet.write(target_row_idx, col_idx + 1, val, yellow_fmt)
            
            worksheet.write(target_row_idx, 0, "æœ€ä½", yellow_fmt)

        print("âœ… Excel ç”Ÿæˆå®Œæ¯•!")

    except Exception as e:
        print(f"âŒ Excel ç”Ÿæˆå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

# å°è£…ä¾›ä¸»ç¨‹åºè°ƒç”¨
def main_task():
    run_scraper()

if __name__ == "__main__":
    main_task()